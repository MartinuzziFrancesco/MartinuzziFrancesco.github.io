<!DOCTYPE html>
<html lang="">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>GSoC week 6: minimum complexity echo state network - Francesco Martinuzzi</title><meta name="Description" content="Francesco Martinuzzi"><meta property="og:title" content="GSoC week 6: minimum complexity echo state network" />
<meta property="og:description" content="Up until now we used reservoir generated mainly through a random process, and this approach requires a lot of fine parameter tuning. And even when the optimal parameters are found, the prediction is run-dependent and can show different results with different generations of the reservoir. Is this the only way possible to contruct an Echo State Network (ESN)? Is there a deterministic way to build a ESN? These are the question posed in [1], and the following post is an illustration of the implementation in ReservoirComputing." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://martinuzzifrancesco.github.io/posts/06_gsoc_week/" />
<meta property="og:image" content="https://martinuzzifrancesco.github.io/logo.png"/>
<meta property="article:published_time" content="2020-07-12T14:37:22+02:00" />
<meta property="article:modified_time" content="2020-07-12T14:37:22+02:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://martinuzzifrancesco.github.io/logo.png"/>

<meta name="twitter:title" content="GSoC week 6: minimum complexity echo state network"/>
<meta name="twitter:description" content="Up until now we used reservoir generated mainly through a random process, and this approach requires a lot of fine parameter tuning. And even when the optimal parameters are found, the prediction is run-dependent and can show different results with different generations of the reservoir. Is this the only way possible to contruct an Echo State Network (ESN)? Is there a deterministic way to build a ESN? These are the question posed in [1], and the following post is an illustration of the implementation in ReservoirComputing."/>
<meta name="application-name" content="Francesco Martinuzzi">
<meta name="apple-mobile-web-app-title" content="Francesco Martinuzzi"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://martinuzzifrancesco.github.io/posts/06_gsoc_week/" /><link rel="prev" href="https://martinuzzifrancesco.github.io/posts/05_gsoc_week/" /><link rel="next" href="https://martinuzzifrancesco.github.io/posts/07_gsoc_week/" /><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/normalize.css@8.0.1/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.13.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.7.2/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "GSoC week 6: minimum complexity echo state network",
        "inLanguage": "",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/martinuzzifrancesco.github.io\/posts\/06_gsoc_week\/"
        },"image": ["https:\/\/martinuzzifrancesco.github.io\/images\/Apple-Devices-Preview.png"],"genre": "posts","wordcount":  1661 ,
        "url": "https:\/\/martinuzzifrancesco.github.io\/posts\/06_gsoc_week\/","datePublished": "2020-07-12T14:37:22+02:00","dateModified": "2020-07-12T14:37:22+02:00","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": {
                    "@type": "ImageObject",
                    "url": "https:\/\/martinuzzifrancesco.github.io\/images\/avatar.png",
                    "width":  892 ,
                    "height":  892 
                }},"author": {
                "@type": "Person",
                "name": "Francesco Martinuzzi"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('light' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'light' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Francesco Martinuzzi">Francesco Martinuzzi</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/" title="What have I done"> Posts </a><a class="menu-item" href="/about/" title="Who am I"> About </a><a class="menu-item" href="/research/" title="What do I do"> Research </a><a class="menu-item" href="/contact/" title="How to reach me"> Contact </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Francesco Martinuzzi">Francesco Martinuzzi</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="What have I done">Posts</a><a class="menu-item" href="/about/" title="Who am I">About</a><a class="menu-item" href="/research/" title="What do I do">Research</a><a class="menu-item" href="/contact/" title="How to reach me">Contact</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">GSoC week 6: minimum complexity echo state network</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>Francesco Martinuzzi</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="12127-712-07">12127-712-07</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;1661 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;8 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#implementation-in-reservoircomputing">Implementation in ReservoirComputing</a></li>
  </ul>

  <ul>
    <li><a href="#one-step-ahead-prediction">One step ahead prediction</a></li>
    <li><a href="#attractor-reconstruction">Attractor reconstruction</a></li>
    <li><a href="#documentation">Documentation</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>Up until now we used reservoir generated mainly through a random process, and this approach requires a lot of fine parameter tuning. And even when the optimal parameters are found, the prediction is run-dependent and can show different results with different generations of the reservoir. Is this the only way possible to contruct an Echo State Network (ESN)? Is there a deterministic way to build a ESN? These are the question posed in <a href="#1" rel="">[1]</a>, and the following post is an illustration of the implementation in ReservoirComputing.jl of their construction of a deterministic input layer and three reservoirs. As always we will quickly lay out the theory, then an example will be given.</p>
<h1 id="minimum-complexity-reservoir-and-input-layer">Minimum complexity reservoir and input layer</h1>
<p>The usual construction of a reservoir implies the creation of a random sparse matrix, with given sparsity and dimension, and following rescaling of the values in order to have set the spectral radius to be under a determined value, usually one, in order to ensure the Echo State Property (ESP) <a href="#2" rel="">[2]</a>. As already stated in the work done in the <a href="https://martinuzzifrancesco.github.io/posts/04_gsoc_week/" target="_blank" rel="noopener noreffer">4th week</a>, this construction, although efficient, could have some downsides. The particular problem we want to solve with the current implementation is the one given by the randomness of the process: both the reservoir and the input layer construction are initially generated as random and later rescaled. The paper we are following for a possible solution <a href="#1" rel="">[1]</a> introduces three different constructions for a deterministic reservoir:</p>
<ul>
<li><strong>Delay Line Reservoir (DLR)</strong>: is composed of units organized in a line. The elements of the lower subdiagonal of the reservoir matrix have non-zero values, and all are the same.</li>
<li><strong>DLR with backward connections (DLRB)</strong>: based on the DLR each reservoir unit is also connected to the preceding neuron. This is obtained setting as non-zero the elements of both the upper and lower subdiagonal, with two different values.</li>
<li><strong>Simple Cycle Reservoir (SCR)</strong>: is composed by units organized in a cycle. The non-zero elements of the reservoir are the lower subdiagonal and the upper right corner, all set to the same weight.</li>
</ul>
<p>In addition to these reservoirs, also a contruction for the input layer is given: all input connections have the same absolute weight and the sign of each value is determined randomly by a draw from a Bernoulli distribution of mean 1/2. In the paper is stated that any other imposition of sign over the input weight deteriorates the results, so a little randomness is manteined even in this construction, but of course is still far from the original implementation.</p>
<h2 id="implementation-in-reservoircomputing">Implementation in ReservoirComputing</h2>
<p>The implementation of the construction of reservoir and input layer as described in the paper is straightforward: following the instructions we created three different functions for the reservoir named <code>DLR()</code>, <code>DLRB()</code> and <code>SCR()</code> that take as input</p>
<ul>
<li><code>res_size</code> the size of the reservoir</li>
<li><code>weight</code> the value for the weights</li>
<li><code>fb_weight</code> the value for the feedback weights, only needed for the <code>DLRB()</code> function.</li>
</ul>
<p>The result of each function is a reservoir matrix with the requested construction. In addition we also added a <code>min_complex_input</code> function, taking as input</p>
<ul>
<li><code>res_size</code> the size of the reservoir</li>
<li><code>in_size</code> the size of the input array</li>
<li><code>weight</code> the value of the weights</li>
</ul>
<p>and giving as output the minimum complexity input layer.</p>
<h1 id="example">Example</h1>
<p>For this example we are goind to use the <a href="https://en.wikipedia.org/wiki/H%C3%A9non_map" target="_blank" rel="noopener noreffer">Henon map</a>, defined as
$$x_{x+1} = 1 - ax_n^2 + y_n$$
$$ y_{n+1} = bx_n $$</p>
<p>The attractor depends on the two values \( a, b \) and shows chaotic behaviour for the classical values of \( a=1.4 \) and \( b=0.3 \).</p>
<p>To obtain a dataset for the Henon map this time we will use the <a href="https://juliadynamics.github.io/DynamicalSystems.jl/latest/" target="_blank" rel="noopener noreffer">DynamicalSystems</a> package. Before starting the work we will need to download all the necessary utilies and import them:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">using</span> <span class="n">Pkg</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&#34;ReservoirComputing&#34;</span><span class="p">)</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&#34;Plots&#34;</span><span class="p">)</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&#34;DynamicalSystems&#34;</span><span class="p">)</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&#34;Statistics&#34;</span><span class="p">)</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&#34;LinearAlgebra&#34;</span><span class="p">)</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&#34;Random&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">using</span> <span class="n">ReservoirComputing</span>
<span class="k">using</span> <span class="n">Plots</span>
<span class="k">using</span> <span class="n">DynamicalSystems</span>
<span class="k">using</span> <span class="n">Statistics</span>
<span class="k">using</span> <span class="n">LinearAlgebra</span>
<span class="k">using</span> <span class="n">Random</span>
</code></pre></td></tr></table>
</div>
</div><p>Now we can generate the Henon map, which will be shifted by -0.5 and scaled by 2, in order to have consistency with the paper. At the same time we are going to wash out any initial transient and construct the training,  <code>train</code>, and testing, <code>test</code>, datasets, following the values given by the paper:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">ds</span> <span class="o">=</span> <span class="n">Systems</span><span class="o">.</span><span class="n">henon</span><span class="p">()</span>
<span class="n">traj</span> <span class="o">=</span> <span class="n">trajectory</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="mi">7000</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="kt">Matrix</span><span class="p">(</span><span class="n">traj</span><span class="p">)</span><span class="o">&#39;</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">data</span> <span class="o">.-</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">.*</span> <span class="mi">2</span>
<span class="n">shift</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">train_len</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">predict_len</span> <span class="o">=</span> <span class="mi">3000</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="n">shift</span><span class="o">:</span><span class="n">shift</span><span class="o">+</span><span class="n">train_len</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="o">:</span><span class="p">,</span> <span class="n">shift</span><span class="o">+</span><span class="n">train_len</span><span class="o">:</span><span class="n">shift</span><span class="o">+</span><span class="n">train_len</span><span class="o">+</span><span class="n">predict_len</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</code></pre></td></tr></table>
</div>
</div><h2 id="one-step-ahead-prediction">One step ahead prediction</h2>
<p>Now we can set the parameters for the construction of the ESN, for which we followed closely the ones given in the paper, outside for the ridge regression value. Note that since some values are corresponding to our default (activation function, alpha and non linear algorithm) we will omit them for clarity.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">approx_res_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">radius</span> <span class="o">=</span> <span class="mf">0.3</span>
<span class="n">sparsity</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mi">1</span><span class="o">*</span><span class="mi">10</span><span class="o">^</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">extended_states</span> <span class="o">=</span> <span class="nb">true</span>

<span class="n">input_weight</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">r</span><span class="o">=</span> <span class="mf">0.95</span>
<span class="n">b</span> <span class="o">=</span> <span class="mf">0.05</span>
</code></pre></td></tr></table>
</div>
</div><p>We can now build both the standard ESN and three other ESNs based on the novel reservoir implementation. We are going to need the four of them for a comparison of the results:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">Random</span><span class="o">.</span><span class="n">seed!</span><span class="p">(</span><span class="mi">17</span><span class="p">)</span> <span class="c">#fixed seed for reproducibility</span>
<span class="nd">@time</span> <span class="n">W</span> <span class="o">=</span> <span class="n">init_reservoir_givensp</span><span class="p">(</span><span class="n">approx_res_size</span><span class="p">,</span> <span class="n">radius</span><span class="p">,</span> <span class="n">sparsity</span><span class="p">)</span>
<span class="n">W_in</span> <span class="o">=</span> <span class="n">init_dense_input_layer</span><span class="p">(</span><span class="n">approx_res_size</span><span class="p">,</span> <span class="n">size</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">sigma</span><span class="p">)</span>
<span class="n">esn</span> <span class="o">=</span> <span class="n">ESN</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">W_in</span><span class="p">,</span> <span class="n">extended_states</span> <span class="o">=</span> <span class="n">extended_states</span><span class="p">)</span>

<span class="n">Winmc</span> <span class="o">=</span> <span class="n">min_complex_input</span><span class="p">(</span><span class="n">size</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">approx_res_size</span><span class="p">,</span> <span class="n">input_weight</span><span class="p">)</span>

<span class="nd">@time</span> <span class="n">Wscr</span> <span class="o">=</span> <span class="n">SCR</span><span class="p">(</span><span class="n">approx_res_size</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
<span class="n">esnscr</span> <span class="o">=</span> <span class="n">ESN</span><span class="p">(</span><span class="n">Wscr</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">Winmc</span><span class="p">,</span> <span class="n">extended_states</span> <span class="o">=</span> <span class="n">extended_states</span><span class="p">)</span>

<span class="nd">@time</span> <span class="n">Wdlrb</span> <span class="o">=</span> <span class="n">DLRB</span><span class="p">(</span><span class="n">approx_res_size</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">esndlrb</span> <span class="o">=</span> <span class="n">ESN</span><span class="p">(</span><span class="n">Wdlrb</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">Winmc</span><span class="p">,</span> <span class="n">extended_states</span> <span class="o">=</span> <span class="n">extended_states</span><span class="p">)</span>

<span class="nd">@time</span> <span class="n">Wdlr</span> <span class="o">=</span> <span class="n">DLR</span><span class="p">(</span><span class="n">approx_res_size</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
<span class="n">esndlr</span> <span class="o">=</span> <span class="n">ESN</span><span class="p">(</span><span class="n">Wdlr</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">Winmc</span><span class="p">,</span> <span class="n">extended_states</span> <span class="o">=</span> <span class="n">extended_states</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">0.012062 seconds (33 allocations: 359.922 KiB)
0.000020 seconds (6 allocations: 78.359 KiB)
0.000019 seconds (6 allocations: 78.359 KiB)
0.000019 seconds (6 allocations: 78.359 KiB)
</code></pre></td></tr></table>
</div>
</div><p>In order to test the accuracy of the predictions given by different architectures we are going to use the Normalized Mean Square Error (NMSE), defined as
$$NMSE = \frac{&lt;||\hat{y}(t)-y(t)||^2&gt;}{&lt;||y(t)-&lt;y(t)&gt;||^2&gt;}$$
where \( \hat{y}(t) \) is the readout output, \( y(t) \) is the target output, \( &lt;\cdot&gt; \) indicates the empirical mean and \( ||\cdot|| \) is the Euclidean norm. A simple <code>NMSE</code> function is created:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-julia" data-lang="julia"><span class="k">function</span> <span class="n">NMSE</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
    <span class="n">num</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">den</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">sums</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="o">:</span><span class="n">size</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">append!</span><span class="p">(</span><span class="n">sums</span><span class="p">,</span> <span class="n">sum</span><span class="p">(</span><span class="n">target</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="o">:</span><span class="p">]))</span>
    <span class="k">end</span>
    <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="o">:</span><span class="n">size</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">num</span> <span class="o">+=</span> <span class="n">norm</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="n">target</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="n">i</span><span class="p">])</span><span class="o">^</span><span class="mf">2.0</span>
        <span class="n">den</span> <span class="o">+=</span> <span class="n">norm</span><span class="p">(</span><span class="n">target</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="n">i</span><span class="p">]</span><span class="o">-</span><span class="n">sums</span><span class="o">./</span><span class="n">size</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">^</span><span class="mf">2.0</span>
    <span class="k">end</span>
    <span class="n">nmse</span> <span class="o">=</span> <span class="p">(</span><span class="n">num</span><span class="o">/</span><span class="n">size</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">den</span><span class="o">/</span><span class="n">size</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">nmse</span>
<span class="k">end</span>
</code></pre></td></tr></table>
</div>
</div><p>Now we can iterate and test the output of all the different implementations in a one step ahead prediction task:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">esns</span> <span class="o">=</span> <span class="p">[</span><span class="n">esn</span><span class="p">,</span> <span class="n">esndlr</span><span class="p">,</span> <span class="n">esndlrb</span><span class="p">,</span> <span class="n">esnscr</span><span class="p">]</span>
<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="n">esns</span>
    <span class="n">W_out</span> <span class="o">=</span> <span class="n">ESNtrain</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">ESNpredict_h_steps</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">predict_len</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">W_out</span><span class="p">)</span>
    <span class="n">println</span><span class="p">(</span><span class="n">NMSE</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">output</span><span class="p">))</span>
<span class="k">end</span>
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-fallback" data-lang="fallback">0.000766235182367319
0.0013015853534120024
0.0011355988458350088
0.001843450482139491
</code></pre></td></tr></table>
</div>
</div><p>The standard ESN shows the best results, but the NMSE given by the minimum complexity ESNs are actually not bad. The results are better than those presented in the paper for all the architectures so they are not directly comparable, but the best performing ESN between the minimum complexity ones seems to be the DLRB-based, something that is also true in the paper.</p>
<h2 id="attractor-reconstruction">Attractor reconstruction</h2>
<p>Now we want to venture into something that is not done in the paper: we want to see if this deterministic implementation of reservoirs and input layers are capable of reconstructing the Henon attractor. We will use the ESNs already built and we will predict the system for <code>predict_len</code> steps to see if the behaviour is manteined. We will do so only through an eye test, but it should suffice to have a general idea of the capabilities of these reservoirs.</p>
<p>To start we will plot the actual data, in order to have something to compare the resuls to:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">scatter</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="o">:</span><span class="p">],</span> <span class="n">test</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="o">:</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">&#34;actual&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://user-images.githubusercontent.com/10376688/87250878-4dda0c80-c468-11ea-8b38-d7071f051363.png"
        data-srcset="https://user-images.githubusercontent.com/10376688/87250878-4dda0c80-c468-11ea-8b38-d7071f051363.png, https://user-images.githubusercontent.com/10376688/87250878-4dda0c80-c468-11ea-8b38-d7071f051363.png 1.5x, https://user-images.githubusercontent.com/10376688/87250878-4dda0c80-c468-11ea-8b38-d7071f051363.png 2x"
        data-sizes="auto"
        alt="https://user-images.githubusercontent.com/10376688/87250878-4dda0c80-c468-11ea-8b38-d7071f051363.png"
        title="actual" /></p>
<p>Now let&rsquo;s see if the standard ESN is able to predict correctly this attractor</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">wout</span> <span class="o">=</span> <span class="n">ESNtrain</span><span class="p">(</span><span class="n">esn</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">ESNpredict</span><span class="p">(</span><span class="n">esn</span><span class="p">,</span> <span class="n">predict_len</span><span class="p">,</span> <span class="n">wout</span><span class="p">)</span>
<span class="n">scatter</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="o">:</span><span class="p">],</span> <span class="n">output</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="o">:</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">&#34;ESN&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://user-images.githubusercontent.com/10376688/87250933-8974d680-c468-11ea-9006-425439668774.png"
        data-srcset="https://user-images.githubusercontent.com/10376688/87250933-8974d680-c468-11ea-9006-425439668774.png, https://user-images.githubusercontent.com/10376688/87250933-8974d680-c468-11ea-9006-425439668774.png 1.5x, https://user-images.githubusercontent.com/10376688/87250933-8974d680-c468-11ea-9006-425439668774.png 2x"
        data-sizes="auto"
        alt="https://user-images.githubusercontent.com/10376688/87250933-8974d680-c468-11ea-9006-425439668774.png"
        title="ESN" /></p>
<p>Not bad, but we already know the capabilities of the ESN. We are here to test the minimum complexity construction, so let us start with DLR</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">wout</span> <span class="o">=</span> <span class="n">ESNtrain</span><span class="p">(</span><span class="n">esndlr</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">ESNpredict</span><span class="p">(</span><span class="n">esndlr</span><span class="p">,</span> <span class="n">predict_len</span><span class="p">,</span> <span class="n">wout</span><span class="p">)</span>
<span class="n">scatter</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="o">:</span><span class="p">],</span> <span class="n">output</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="o">:</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">&#34;ESN-DLR&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://user-images.githubusercontent.com/10376688/87250941-9396d500-c468-11ea-910b-94ec2f5e5956.png"
        data-srcset="https://user-images.githubusercontent.com/10376688/87250941-9396d500-c468-11ea-910b-94ec2f5e5956.png, https://user-images.githubusercontent.com/10376688/87250941-9396d500-c468-11ea-910b-94ec2f5e5956.png 1.5x, https://user-images.githubusercontent.com/10376688/87250941-9396d500-c468-11ea-910b-94ec2f5e5956.png 2x"
        data-sizes="auto"
        alt="https://user-images.githubusercontent.com/10376688/87250941-9396d500-c468-11ea-910b-94ec2f5e5956.png"
        title="ESN-DLR" /></p>
<p>The predictions are not as clear cut as we would like, but the behaviour is manteined nevertheless. Actually impressive considering the simple construction of the reservoir. Trying the two other constructions gives the following:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">wout</span> <span class="o">=</span> <span class="n">ESNtrain</span><span class="p">(</span><span class="n">esndlrb</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">ESNpredict</span><span class="p">(</span><span class="n">esndlrb</span><span class="p">,</span> <span class="n">predict_len</span><span class="p">,</span> <span class="n">wout</span><span class="p">)</span>
<span class="n">scatter</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="o">:</span><span class="p">],</span> <span class="n">output</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="o">:</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">&#34;ESN-DLRB&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://user-images.githubusercontent.com/10376688/87250958-9f829700-c468-11ea-8721-194a1d1f3025.png"
        data-srcset="https://user-images.githubusercontent.com/10376688/87250958-9f829700-c468-11ea-8721-194a1d1f3025.png, https://user-images.githubusercontent.com/10376688/87250958-9f829700-c468-11ea-8721-194a1d1f3025.png 1.5x, https://user-images.githubusercontent.com/10376688/87250958-9f829700-c468-11ea-8721-194a1d1f3025.png 2x"
        data-sizes="auto"
        alt="https://user-images.githubusercontent.com/10376688/87250958-9f829700-c468-11ea-8721-194a1d1f3025.png"
        title="ESN-DLRB" /></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-julia" data-lang="julia"><span class="n">wout</span> <span class="o">=</span> <span class="n">ESNtrain</span><span class="p">(</span><span class="n">esnscr</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">ESNpredict</span><span class="p">(</span><span class="n">esnscr</span><span class="p">,</span> <span class="n">predict_len</span><span class="p">,</span> <span class="n">wout</span><span class="p">)</span>
<span class="n">scatter</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="o">:</span><span class="p">],</span> <span class="n">output</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="o">:</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">&#34;ESN-SCR&#34;</span><span class="p">)</span>
</code></pre></td></tr></table>
</div>
</div><p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://user-images.githubusercontent.com/10376688/87250962-a6a9a500-c468-11ea-962a-21ad28695afd.png"
        data-srcset="https://user-images.githubusercontent.com/10376688/87250962-a6a9a500-c468-11ea-962a-21ad28695afd.png, https://user-images.githubusercontent.com/10376688/87250962-a6a9a500-c468-11ea-962a-21ad28695afd.png 1.5x, https://user-images.githubusercontent.com/10376688/87250962-a6a9a500-c468-11ea-962a-21ad28695afd.png 2x"
        data-sizes="auto"
        alt="https://user-images.githubusercontent.com/10376688/87250962-a6a9a500-c468-11ea-962a-21ad28695afd.png"
        title="ESN-SCR" /></p>
<p>The results are somewhat similar between each other, and a deeper quantitative analysis is needed to determine the best performing construction, but this was not the aim of this post. We wanted to see if these basic implementations of reservoirs and input layers were capable not only of maintaining a short term prediction capability, but also if they were still able to mimic the behaviour of a chaotic attractor in the long term and it seems that both of these statements are proven to be correct. This seminal paper not only sheds light on the still inexplored possibilities of ESN reservoir constructions, but also shows that very little complexity is needed for this model to obtain very good results in a short amount of time.</p>
<p>As always, if you have any questions regarding the model, the package or you have found errors in my post, please donâ€™t hesitate to contact me!</p>
<h2 id="documentation">Documentation</h2>
<p><a id="1">[1]</a>
Rodan, Ali, and Peter Tino. &ldquo;Minimum complexity echo state network.&rdquo; IEEE transactions on neural networks 22.1 (2010): 131-144.</p>
<p><a id="2">[2]</a>
Yildiz, Izzet B., Herbert Jaeger, and Stefan J. Kiebel. &ldquo;Re-visiting the echo state property.&rdquo; Neural networks 35 (2012): 1-9.</p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 12127-712-07</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/posts/06_gsoc_week/index.md" target="_blank">Read Markdown</a>
                        </span></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/05_gsoc_week/" class="prev" rel="prev" title="Data-driven prediction of chaotic systems: comparison of Echo State Network variations "><i class="fas fa-angle-left fa-fw"></i>Data-driven prediction of chaotic systems: comparison of Echo State Network variations </a>
            <a href="/posts/07_gsoc_week/" class="next" rel="next" title="GSoC week 7: Reservoir Computing with Cellular Automata Part 1">GSoC week 7: Reservoir Computing with Cellular Automata Part 1<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2020 - 2022</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">Francesco Martinuzzi</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.css"><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/smooth-scroll@16.1.3/dist/smooth-scroll.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.2.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/copy-tex.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
