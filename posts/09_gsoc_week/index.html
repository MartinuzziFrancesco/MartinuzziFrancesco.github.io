<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>GSoC week 9: Cycle Reservoirs with Regular Jumps | Francesco Martinuzzi</title><meta name=keywords content><meta name=description content="This week body of work is less then the usual amount, since most of my time was spent watching the incredible talks given at JuliaCon 2020. This was my first time attending and I just wanted to spend a few lines congratulating all the speakers for the amazing work they are doing with Julia, and most importantly I wanted to thank the organizers for the fantastic job they did: it really felt like an actual physical conference and the sense of community was truly awesome to experience."><meta name=author content="Francesco Martinuzzi"><link rel=canonical href=https://martinuzzifrancesco.github.io/posts/09_gsoc_week/><link crossorigin=anonymous href=/assets/css/stylesheet.849fd8bd636f9bdcc8fd3087509c431a61faae78bd735e7ba75e6fd13ec64f83.css integrity="sha256-hJ/YvWNvm9zI/TCHUJxDGmH6rni9c157p15v0T7GT4M=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://martinuzzifrancesco.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://martinuzzifrancesco.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://martinuzzifrancesco.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://martinuzzifrancesco.github.io/apple-touch-icon.png><link rel=mask-icon href=https://martinuzzifrancesco.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="GSoC week 9: Cycle Reservoirs with Regular Jumps"><meta property="og:description" content="This week body of work is less then the usual amount, since most of my time was spent watching the incredible talks given at JuliaCon 2020. This was my first time attending and I just wanted to spend a few lines congratulating all the speakers for the amazing work they are doing with Julia, and most importantly I wanted to thank the organizers for the fantastic job they did: it really felt like an actual physical conference and the sense of community was truly awesome to experience."><meta property="og:type" content="article"><meta property="og:url" content="https://martinuzzifrancesco.github.io/posts/09_gsoc_week/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-08-02T16:45:38+02:00"><meta property="article:modified_time" content="2020-08-02T16:45:38+02:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="GSoC week 9: Cycle Reservoirs with Regular Jumps"><meta name=twitter:description content="This week body of work is less then the usual amount, since most of my time was spent watching the incredible talks given at JuliaCon 2020. This was my first time attending and I just wanted to spend a few lines congratulating all the speakers for the amazing work they are doing with Julia, and most importantly I wanted to thank the organizers for the fantastic job they did: it really felt like an actual physical conference and the sense of community was truly awesome to experience."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://martinuzzifrancesco.github.io/posts/"},{"@type":"ListItem","position":2,"name":"GSoC week 9: Cycle Reservoirs with Regular Jumps","item":"https://martinuzzifrancesco.github.io/posts/09_gsoc_week/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"GSoC week 9: Cycle Reservoirs with Regular Jumps","name":"GSoC week 9: Cycle Reservoirs with Regular Jumps","description":"This week body of work is less then the usual amount, since most of my time was spent watching the incredible talks given at JuliaCon 2020. This was my first time attending and I just wanted to spend a few lines congratulating all the speakers for the amazing work they are doing with Julia, and most importantly I wanted to thank the organizers for the fantastic job they did: it really felt like an actual physical conference and the sense of community was truly awesome to experience.","keywords":[],"articleBody":"This week body of work is less then the usual amount, since most of my time was spent watching the incredible talks given at JuliaCon 2020. This was my first time attending and I just wanted to spend a few lines congratulating all the speakers for the amazing work they are doing with Julia, and most importantly I wanted to thank the organizers for the fantastic job they did: it really felt like an actual physical conference and the sense of community was truly awesome to experience.\nIn the middle of all the talks I was still able to read a couple of papers and write some code, and this week work is a companion to the work done in week 6: expanding the research done in their previous article [1], they constructed a different type of cycle reservoir with random jumps and a different way to create an input layer [2]. In this post we will discuss the theory expressed in the paper and, after explaining the implementation in ReservoirComputing.jl, we will show how this construction performs on the tasks we takled in week 6.\nCycle Reservoirs with Jumps and irrational sign input layer The costruction of Cycle Reservoirs with Jumps (CRJ) builds over the idea of the Simple Cycle Reservoir (SCR): contrary to the stadard construction of an Echo State Network (ESN) standard reservoir the two algorithms proposed are completely deterministic and really simple in nature. In the CRJ model the reservoir nodes are connected in a unidirectional cycle, as they are in the SCR model, with bidirectional shortcuts (called jumps). The value for the cycle connections are the same \\( r_c \u003e 0 \\), and all the jumps also share the same values \\( r_j \u003e 0 \\). The construction of the CRJ reservoir can be described in the following way:\nThe lower subdiagonal of the reservoir \\( \\textbf{W} \\) is equal to the chosen \\( r_c \\) The upper right corner of reservoir \\( \\textbf{W} \\) is equal to the chosen \\( r_c \\) With a chosen jump size \\( 1 \u003c l \u003c [N/2] \\) if \\( (N \\text{mod}l) = 0 \\) then there are \\( [N/l] \\) jumps, the first being from unit 1 to unit \\( 1+l \\), the last from unit \\( N+1-l \\) to unit 1. If \\( (N \\text{mod}l) \\ne 0 \\) then there are \\( [N/l] \\) jumps, the last jump ending in unit \\( N+1-(N\\text{mod}l) \\). All the jumps have the same chosen value \\( r_j \\) Along with the construction of the CRJ model the paper [2] proposes a fully connected input layer with the same absolute value of the connection weight. The sign of the input weights is determined using the decimal expansion of an irrational number, \\( \\pi \\) being the choice of the authors. The first \\( N \\) digits \\( d_1, d_2,…,d_N \\) are taken and if \\( 0 \\le d_n \\le 4 \\) then the nth input will have sign - (minus), else if \\( 5 \\le d_n \\le 9 \\) it will have a + (plus) sign.\nImplementation in ReservoirComputing A new function called CRJ() has been added to the reservoirs construction; this function takes as input\nres_size the size of the reservior cyrcle_weight the value of the weights \\( r_c \\) jump_weight the value of the weights \\( r_j \\) jump_size the number of jumps \\( l \\) and gives as output a reservoir matrix. In addition a function for the construction of the input layer has also been added. Denominated irrational_sign_input() it takes as input\nres_size the size of the reservior in_size the size of the input vector weight the absolute value of the connection weight irrational an optionl input, with default \\( \\pi \\), used for the determination of the sign for the connection weights Example To remain in line with the work done in the 6th week, and in order to be able to do a meaningful comparison, we are going to use the Henon map for our tests. The Henon map is defined as\n$$x_{x+1} = 1 - ax_n^2 + y_n$$ $$ y_{n+1} = bx_n $$\nTo obtaine the data for out tests we are going to use DynamicalSystems.jl. Before starting the work let’s download and inport all useful packages\nusing Pkg Pkg.add(\"ReservoirComputing\") Pkg.add(\"Plots\") Pkg.add(\"DynamicalSystems\") Pkg.add(\"LinearAlgebra\") Pkg.add(\"Random\") using ReservoirComputing using Plots using DynamicalSystems using LinearAlgebra using Random Now we can generate the Henon map, and we will shift the data points by -0.5 and scale them by 2 to reproduce the data we had last time. The initial transient will be washed out and we will create two datasets called train and test:\nds = Systems.henon() traj = trajectory(ds, 7000) data = Matrix(traj)' data = (data .-0.5) .* 2 shift = 200 train_len = 2000 predict_len = 3000 train = data[:, shift:shift+train_len-1] test = data[:, shift+train_len:shift+train_len+predict_len-1] Having the needed data we can proceed to the prediction tasks.\nOne step ahead prediction For sake of comparison we are going to use the same values as last time for the construction of the ESN:\napprox_res_size = 100 radius = 0.3 sparsity = 0.5 sigma = 1.0 beta = 1*10^(-1) extended_states = true input_weight = 0.95 cyrcle_weight = 0.95 jump_weight = 0.2 jumps = 5 Since this task was not used in the paper [2] the new parameters jump_weight and jumps are obtained using a manual grid search and as such are probably not as optimized as the other values. We can proceed to the construction of the ESN with the CRJ reservoir and irrational-determined input layer:\n@time W = CRJ(approx_res_size, cyrcle_weight, jump_weight, jumps) W_in = irrational_sign_input(approx_res_size, size(train, 1), input_weight) esn_crj = ESN(W, train, W_in, extended_states = extended_states) 0.000053 seconds (6 allocations: 78.359 KiB) Following the procedure we used lst time, in order to test the accuracy of the prediction we are going to use the Normalized Mean Square Error (NMSE), defined as\n$$NMSE = \\frac{\u003c||\\hat{y}(t)-y(t)||^2\u003e}{\u003c||y(t)-||^2\u003e}$$\nwhere\n\\( \\hat{y}(t) \\) is the readout output \\( y(t) \\) is the target output \\( \u003c\\cdot\u003e \\) indicates the empirical mean \\( ||\\cdot|| \\) is the Euclidean norm. A simple NMSE function can be created following:\nfunction NMSE(target, output) num = 0.0 den = 0.0 sums = [] for i=1:size(target, 1) append!(sums, sum(target[i,:])) end for i=1:size(target, 2) num += norm(output[:,i]-target[:,i])^2.0 den += norm(target[:,i]-sums./size(target, 2))^2.0 end nmse = (num/size(target, 2))/(den/size(target, 2)) return nmse end Testing the one step ahead predicting capabilities of this new implementation we obtain:\nwout = ESNtrain(esn_crj, beta) output = ESNpredict_h_steps(esn_crj, predict_len, 1, test, wout) println(NMSE(test, output)) 0.0010032069150514866 This result outperforms all the architectures tested in week 6, getting a little closer to the standard ESN implementation result. Even though this task is not present in the paper the better results shows that the implementation is valid nevertheless.\nAttractor reconstruction Following the work done in week 6 we want to explore the capabilities of this construction in the reconstruction of the chaotic attractor of the Henon map. Using the already built ESN we will predict the system for predict_len steps and at the end we will plot the results to see if they are in line with the one obtained with the other architectures. To refresh our memory we will start by plotting the actual Henon map:\nscatter(test[1,:], test[2,:], label=\"actual\") Let’s see if the CRJ-based ESN is capable of reproducing the climate of this attractor:\nwout = ESNtrain(esn_crj, beta) output = ESNpredict(esn_crj, predict_len, wout) scatter(output[1,:], output[2, :], lable = \"ESN-CRJ\") The result is actually more clear cut then the results obtained in the 6th week. This architecture seems to be able to represent the attractor in a more precise manner. Both the tests we have done have resulted in a better performance with respect to the other deterministic constructions for reservoirs and input layer. A more statistical accurate exploration is of course needed but both our results and the results found in the paper show the capabilities of this new implementation of a deterministic reservoir.\nAs always, if you have any questions regarding the model, the package or you have found errors in my post, please don’t hesitate to contact me!\nCiting Part of the work done for this project has been published. If this post or the ReservoirComputing.jl software has been helpful, please consider citing the accompanying paper:\n@article{JMLR:v23:22-0611, author = {Francesco Martinuzzi and Chris Rackauckas and Anas Abdelrehim and Miguel D. Mahecha and Karin Mora}, title = {ReservoirComputing.jl: An Efficient and Modular Library for Reservoir Computing Models}, journal = {Journal of Machine Learning Research}, year = {2022}, volume = {23}, number = {288}, pages = {1--8}, url = {http://jmlr.org/papers/v23/22-0611.html} } Documentation [1] Rodan, Ali, and Peter Tino. “Minimum complexity echo state network.” IEEE transactions on neural networks 22.1 (2010): 131-144.\n[2] Rodan, Ali, and Peter Tiňo. “Simple deterministically constructed cycle reservoirs with regular jumps.” Neural computation 24.7 (2012): 1822-1852.\n","wordCount":"1471","inLanguage":"en","datePublished":"2020-08-02T16:45:38+02:00","dateModified":"2020-08-02T16:45:38+02:00","author":{"@type":"Person","name":"Francesco Martinuzzi"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://martinuzzifrancesco.github.io/posts/09_gsoc_week/"},"publisher":{"@type":"Organization","name":"Francesco Martinuzzi","logo":{"@type":"ImageObject","url":"https://martinuzzifrancesco.github.io/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://martinuzzifrancesco.github.io/ accesskey=h title="Francesco Martinuzzi (Alt + H)">Francesco Martinuzzi</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://martinuzzifrancesco.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://martinuzzifrancesco.github.io/research/ title=Research><span>Research</span></a></li><li><a href=https://martinuzzifrancesco.github.io/contact/ title=Contact><span>Contact</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>GSoC week 9: Cycle Reservoirs with Regular Jumps</h1><div class=post-meta><span title='2020-08-02 16:45:38 +0200 CEST'>August 2, 2020</span>&nbsp;·&nbsp;Francesco Martinuzzi</div></header><div class=post-content><p>This week body of work is less then the usual amount, since most of my time was spent watching the incredible talks given at <a href=https://juliacon.org/2020/>JuliaCon 2020</a>. This was my first time attending and I just wanted to spend a few lines congratulating all the speakers for the amazing work they are doing with Julia, and most importantly I wanted to thank the organizers for the fantastic job they did: it really felt like an actual physical conference and the sense of community was truly awesome to experience.</p><p>In the middle of all the talks I was still able to read a couple of papers and write some code, and this week work is a companion to the work done in <a href=https://martinuzzifrancesco.github.io/posts/06_gsoc_week/>week 6</a>: expanding the research done in their previous article <a href=#1>[1]</a>, they constructed a different type of cycle reservoir with random jumps and a different way to create an input layer <a href=#2>[2]</a>. In this post we will discuss the theory expressed in the paper and, after explaining the implementation in ReservoirComputing.jl, we will show how this construction performs on the tasks we takled in week 6.</p><h1 id=cycle-reservoirs-with-jumps-and-irrational-sign-input-layer>Cycle Reservoirs with Jumps and irrational sign input layer<a hidden class=anchor aria-hidden=true href=#cycle-reservoirs-with-jumps-and-irrational-sign-input-layer>#</a></h1><p>The costruction of Cycle Reservoirs with Jumps (CRJ) builds over the idea of the Simple Cycle Reservoir (SCR): contrary to the stadard construction of an Echo State Network (ESN) standard reservoir the two algorithms proposed are completely deterministic and really simple in nature. In the CRJ model the reservoir nodes are connected in a unidirectional cycle, as they are in the SCR model, with bidirectional shortcuts (called jumps). The value for the cycle connections are the same \( r_c > 0 \), and all the jumps also share the same values \( r_j > 0 \). The construction of the CRJ reservoir can be described in the following way:</p><ul><li>The lower subdiagonal of the reservoir \( \textbf{W} \) is equal to the chosen \( r_c \)</li><li>The upper right corner of reservoir \( \textbf{W} \) is equal to the chosen \( r_c \)</li><li>With a chosen jump size \( 1 &lt; l &lt; [N/2] \) if \( (N \text{mod}l) = 0 \) then there are \( [N/l] \) jumps, the first being from unit 1 to unit \( 1+l \), the last from unit \( N+1-l \) to unit 1. If \( (N \text{mod}l) \ne 0 \) then there are \( [N/l] \) jumps, the last jump ending in unit \( N+1-(N\text{mod}l) \). All the jumps have the same chosen value \( r_j \)</li></ul><p>Along with the construction of the CRJ model the paper <a href=#2>[2]</a> proposes a fully connected input layer with the same absolute value of the connection weight. The sign of the input weights is determined using the decimal expansion of an irrational number, \( \pi \) being the choice of the authors. The first \( N \) digits \( d_1, d_2,&mldr;,d_N \) are taken and if \( 0 \le d_n \le 4 \) then the nth input will have sign - (minus), else if \( 5 \le d_n \le 9 \) it will have a + (plus) sign.</p><h2 id=implementation-in-reservoircomputing>Implementation in ReservoirComputing<a hidden class=anchor aria-hidden=true href=#implementation-in-reservoircomputing>#</a></h2><p>A new function called <code>CRJ()</code> has been added to the reservoirs construction; this function takes as input</p><ul><li><code>res_size</code> the size of the reservior</li><li><code>cyrcle_weight</code> the value of the weights \( r_c \)</li><li><code>jump_weight</code> the value of the weights \( r_j \)</li><li><code>jump_size</code> the number of jumps \( l \)</li></ul><p>and gives as output a reservoir matrix. In addition a function for the construction of the input layer has also been added. Denominated <code>irrational_sign_input()</code> it takes as input</p><ul><li><code>res_size</code> the size of the reservior</li><li><code>in_size</code> the size of the input vector</li><li><code>weight</code> the absolute value of the connection weight</li><li><code>irrational</code> an optionl input, with default \( \pi \), used for the determination of the sign for the connection weights</li></ul><h1 id=example>Example<a hidden class=anchor aria-hidden=true href=#example>#</a></h1><p>To remain in line with the work done in the 6th week, and in order to be able to do a meaningful comparison, we are going to use the <a href=https://en.wikipedia.org/wiki/H%C3%A9non_map>Henon map</a> for our tests. The Henon map is defined as</p><p>$$x_{x+1} = 1 - ax_n^2 + y_n$$
$$ y_{n+1} = bx_n $$</p><p>To obtaine the data for out tests we are going to use DynamicalSystems.jl. Before starting the work let&rsquo;s download and inport all useful packages</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span><span style=color:#66d9ef>using</span> Pkg
</span></span><span style=display:flex><span>Pkg<span style=color:#f92672>.</span>add(<span style=color:#e6db74>&#34;ReservoirComputing&#34;</span>)
</span></span><span style=display:flex><span>Pkg<span style=color:#f92672>.</span>add(<span style=color:#e6db74>&#34;Plots&#34;</span>)
</span></span><span style=display:flex><span>Pkg<span style=color:#f92672>.</span>add(<span style=color:#e6db74>&#34;DynamicalSystems&#34;</span>)
</span></span><span style=display:flex><span>Pkg<span style=color:#f92672>.</span>add(<span style=color:#e6db74>&#34;LinearAlgebra&#34;</span>)
</span></span><span style=display:flex><span>Pkg<span style=color:#f92672>.</span>add(<span style=color:#e6db74>&#34;Random&#34;</span>)
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span><span style=color:#66d9ef>using</span> ReservoirComputing
</span></span><span style=display:flex><span><span style=color:#66d9ef>using</span> Plots
</span></span><span style=display:flex><span><span style=color:#66d9ef>using</span> DynamicalSystems
</span></span><span style=display:flex><span><span style=color:#66d9ef>using</span> LinearAlgebra
</span></span><span style=display:flex><span><span style=color:#66d9ef>using</span> Random
</span></span></code></pre></div><p>Now we can generate the Henon map, and we will shift the data points by -0.5 and scale them by 2 to reproduce the data we had last time. The initial transient will be washed out and we will create two datasets called <code>train</code> and <code>test</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span>ds <span style=color:#f92672>=</span> Systems<span style=color:#f92672>.</span>henon()
</span></span><span style=display:flex><span>traj <span style=color:#f92672>=</span> trajectory(ds, <span style=color:#ae81ff>7000</span>)
</span></span><span style=display:flex><span>data <span style=color:#f92672>=</span> <span style=color:#66d9ef>Matrix</span>(traj)<span style=color:#f92672>&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>data <span style=color:#f92672>=</span> (data <span style=color:#f92672>.-</span><span style=color:#ae81ff>0.5</span>) <span style=color:#f92672>.*</span> <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>shift <span style=color:#f92672>=</span> <span style=color:#ae81ff>200</span>
</span></span><span style=display:flex><span>train_len <span style=color:#f92672>=</span> <span style=color:#ae81ff>2000</span>
</span></span><span style=display:flex><span>predict_len <span style=color:#f92672>=</span> <span style=color:#ae81ff>3000</span>
</span></span><span style=display:flex><span>train <span style=color:#f92672>=</span> data[<span style=color:#f92672>:</span>, shift<span style=color:#f92672>:</span>shift<span style=color:#f92672>+</span>train_len<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]
</span></span><span style=display:flex><span>test <span style=color:#f92672>=</span> data[<span style=color:#f92672>:</span>, shift<span style=color:#f92672>+</span>train_len<span style=color:#f92672>:</span>shift<span style=color:#f92672>+</span>train_len<span style=color:#f92672>+</span>predict_len<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]
</span></span></code></pre></div><p>Having the needed data we can proceed to the prediction tasks.</p><h2 id=one-step-ahead-prediction>One step ahead prediction<a hidden class=anchor aria-hidden=true href=#one-step-ahead-prediction>#</a></h2><p>For sake of comparison we are going to use the same values as last time for the construction of the ESN:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span>approx_res_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>100</span>
</span></span><span style=display:flex><span>radius <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.3</span>
</span></span><span style=display:flex><span>sparsity <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.5</span>
</span></span><span style=display:flex><span>sigma <span style=color:#f92672>=</span> <span style=color:#ae81ff>1.0</span>
</span></span><span style=display:flex><span>beta <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span><span style=color:#f92672>*</span><span style=color:#ae81ff>10</span><span style=color:#f92672>^</span>(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>extended_states <span style=color:#f92672>=</span> true
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>input_weight <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.95</span>
</span></span><span style=display:flex><span>cyrcle_weight <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.95</span>
</span></span><span style=display:flex><span>jump_weight <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.2</span>
</span></span><span style=display:flex><span>jumps <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>
</span></span></code></pre></div><p>Since this task was not used in the paper <a href=#2>[2]</a> the new parameters <code>jump_weight</code> and <code>jumps</code> are obtained using a manual grid search and as such are probably not as optimized as the other values. We can proceed to the construction of the ESN with the CRJ reservoir and irrational-determined input layer:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span><span style=color:#a6e22e>@time</span> W <span style=color:#f92672>=</span> CRJ(approx_res_size, cyrcle_weight, jump_weight, jumps)
</span></span><span style=display:flex><span>W_in <span style=color:#f92672>=</span> irrational_sign_input(approx_res_size, size(train, <span style=color:#ae81ff>1</span>), input_weight)
</span></span><span style=display:flex><span>esn_crj <span style=color:#f92672>=</span> ESN(W, train, W_in, extended_states <span style=color:#f92672>=</span> extended_states)
</span></span></code></pre></div><pre tabindex=0><code>0.000053 seconds (6 allocations: 78.359 KiB)
</code></pre><p>Following the procedure we used lst time, in order to test the accuracy of the prediction we are going to use the Normalized Mean Square Error (NMSE), defined as</p><p>$$NMSE = \frac{&lt;||\hat{y}(t)-y(t)||^2>}{&lt;||y(t)-&lt;y(t)>||^2>}$$</p><p>where</p><ul><li>\( \hat{y}(t) \) is the readout output</li><li>\( y(t) \) is the target output</li><li>\( &lt;\cdot> \) indicates the empirical mean</li><li>\( ||\cdot|| \) is the Euclidean norm.</li></ul><p>A simple <code>NMSE</code> function can be created following:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span><span style=color:#66d9ef>function</span> NMSE(target, output)
</span></span><span style=display:flex><span>    num <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.0</span>
</span></span><span style=display:flex><span>    den <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.0</span>
</span></span><span style=display:flex><span>    sums <span style=color:#f92672>=</span> []
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span><span style=color:#f92672>:</span>size(target, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        append!(sums, sum(target[i,<span style=color:#f92672>:</span>]))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> i<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span><span style=color:#f92672>:</span>size(target, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span>        num <span style=color:#f92672>+=</span> norm(output[<span style=color:#f92672>:</span>,i]<span style=color:#f92672>-</span>target[<span style=color:#f92672>:</span>,i])<span style=color:#f92672>^</span><span style=color:#ae81ff>2.0</span>
</span></span><span style=display:flex><span>        den <span style=color:#f92672>+=</span> norm(target[<span style=color:#f92672>:</span>,i]<span style=color:#f92672>-</span>sums<span style=color:#f92672>./</span>size(target, <span style=color:#ae81ff>2</span>))<span style=color:#f92672>^</span><span style=color:#ae81ff>2.0</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>end</span>
</span></span><span style=display:flex><span>    nmse <span style=color:#f92672>=</span> (num<span style=color:#f92672>/</span>size(target, <span style=color:#ae81ff>2</span>))<span style=color:#f92672>/</span>(den<span style=color:#f92672>/</span>size(target, <span style=color:#ae81ff>2</span>))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> nmse
</span></span><span style=display:flex><span><span style=color:#66d9ef>end</span>
</span></span></code></pre></div><p>Testing the one step ahead predicting capabilities of this new implementation we obtain:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span>wout <span style=color:#f92672>=</span> ESNtrain(esn_crj, beta)
</span></span><span style=display:flex><span>output <span style=color:#f92672>=</span> ESNpredict_h_steps(esn_crj, predict_len, <span style=color:#ae81ff>1</span>, test, wout)
</span></span><span style=display:flex><span>println(NMSE(test, output))
</span></span></code></pre></div><pre tabindex=0><code>0.0010032069150514866
</code></pre><p>This result outperforms all the architectures tested in week 6, getting a little closer to the standard ESN implementation result. Even though this task is not present in the paper the better results shows that the implementation is valid nevertheless.</p><h2 id=attractor-reconstruction>Attractor reconstruction<a hidden class=anchor aria-hidden=true href=#attractor-reconstruction>#</a></h2><p>Following the work done in week 6 we want to explore the capabilities of this construction in the reconstruction of the chaotic attractor of the Henon map. Using the already built <code>ESN</code> we will predict the system for <code>predict_len</code> steps and at the end we will plot the results to see if they are in line with the one obtained with the other architectures. To refresh our memory we will start by plotting the actual Henon map:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span>scatter(test[<span style=color:#ae81ff>1</span>,<span style=color:#f92672>:</span>], test[<span style=color:#ae81ff>2</span>,<span style=color:#f92672>:</span>], label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;actual&#34;</span>)
</span></span></code></pre></div><p><img loading=lazy src=https://user-images.githubusercontent.com/10376688/87250878-4dda0c80-c468-11ea-8b38-d7071f051363.png alt=actual></p><p>Let&rsquo;s see if the CRJ-based ESN is capable of reproducing the climate of this attractor:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-julia data-lang=julia><span style=display:flex><span>wout <span style=color:#f92672>=</span> ESNtrain(esn_crj, beta)
</span></span><span style=display:flex><span>output <span style=color:#f92672>=</span> ESNpredict(esn_crj, predict_len, wout)
</span></span><span style=display:flex><span>scatter(output[<span style=color:#ae81ff>1</span>,<span style=color:#f92672>:</span>], output[<span style=color:#ae81ff>2</span>, <span style=color:#f92672>:</span>], lable <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;ESN-CRJ&#34;</span>)
</span></span></code></pre></div><p><img loading=lazy src=https://user-images.githubusercontent.com/10376688/89126754-852c5e00-d4e8-11ea-9e9f-c4ca21229d44.png alt=ESN-CRJ></p><p>The result is actually more clear cut then the results obtained in the 6th week. This architecture seems to be able to represent the attractor in a more precise manner. Both the tests we have done have resulted in a better performance with respect to the other deterministic constructions for reservoirs and input layer. A more statistical accurate exploration is of course needed but both our results and the results found in the paper show the capabilities of this new implementation of a deterministic reservoir.</p><p>As always, if you have any questions regarding the model, the package or you have found errors in my post, please don’t hesitate to contact me!</p><h2 id=citing>Citing<a hidden class=anchor aria-hidden=true href=#citing>#</a></h2><p>Part of the work done for this project has been published. If this post or the ReservoirComputing.jl software has been helpful, please consider citing the accompanying paper:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bibtex data-lang=bibtex><span style=display:flex><span><span style=color:#a6e22e>@article</span>{JMLR:v23:22-0611,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>author</span>  = <span style=color:#e6db74>{Francesco Martinuzzi and Chris Rackauckas and Anas Abdelrehim and Miguel D. Mahecha and Karin Mora}</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>title</span>   = <span style=color:#e6db74>{ReservoirComputing.jl: An Efficient and Modular Library for Reservoir Computing Models}</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>journal</span> = <span style=color:#e6db74>{Journal of Machine Learning Research}</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>year</span>    = <span style=color:#e6db74>{2022}</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>volume</span>  = <span style=color:#e6db74>{23}</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>number</span>  = <span style=color:#e6db74>{288}</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>pages</span>   = <span style=color:#e6db74>{1--8}</span>,
</span></span><span style=display:flex><span>  <span style=color:#a6e22e>url</span>     = <span style=color:#e6db74>{http://jmlr.org/papers/v23/22-0611.html}</span>
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=documentation>Documentation<a hidden class=anchor aria-hidden=true href=#documentation>#</a></h2><p>[1]
Rodan, Ali, and Peter Tino. &ldquo;Minimum complexity echo state network.&rdquo; IEEE transactions on neural networks 22.1 (2010): 131-144.</p><p>[2]
Rodan, Ali, and Peter Tiňo. &ldquo;Simple deterministically constructed cycle reservoirs with regular jumps.&rdquo; Neural computation 24.7 (2012): 1822-1852.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://martinuzzifrancesco.github.io/>Francesco Martinuzzi</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>